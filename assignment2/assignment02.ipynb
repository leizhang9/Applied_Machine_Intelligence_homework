{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe6cb30-f39b-4124-a06c-5b0b91e88bf9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07d6374cb30a40331d76828b595de67a",
     "grade": false,
     "grade_id": "cell-9778f17cc6ae4cb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Second assignment\n",
    "The assignment provides problems regarding basic applications of linear algebra and machine learning. Use this notebook to perform the computations and insert your comments into it. All the coding must be done in Python 3. \n",
    "\n",
    "The assignment has to be submitted individually!\n",
    "\n",
    "All your plots have to be labelled properly!  (Non-labeled plots will result in point deductions!)\n",
    "\n",
    "**Non running cells/tasks will not be considered!**\n",
    "\n",
    "The tasks/questions are 1.1), 1.2), 1.3), 1.4), 1.5), 1.6), 2.1), 2.2), 2.3), 2.4) and 2.5). After each task description there is an answer cell for your code or text. For coding tasks they look like this:\n",
    "\n",
    "```\n",
    "# YOUR CODE HERE\n",
    "```\n",
    "(You can delete the \"YOUR CODE HERE\" comment, if you like.)\n",
    "\n",
    "For markdown (text) cells the response cell will include this:\n",
    "\n",
    "**WRITE YOUR ANSWER HERE**\n",
    "\n",
    "Sometimes they are followed by test cells. You can run the test cells after you finished the task. If these cells don't show any errors, your answer is right. You can't/shouldn't edit test cells!\n",
    "\n",
    "After you finished the notebook you can hit the \"Validate\" button on the top of the notebook to see if all test are good. You can also use the \"Validate\" button on the \"Assignment\" tap on the main page of python.ldv.ei.tum.de. Some tasks will be graded manually (e.g. plots, text answers). They don't have a following test cell. \n",
    "\n",
    "Please make sure to hit the \"Submit\" button on the \"Assignment\" tab on the main page of python.ldv.ei.tum.de before the deadline passes. You will get your final score after the deadline.\n",
    "\n",
    "**Some tips:**\n",
    "- Only change cells with `# YOUR CODE HERE` or **WRITE YOUR ANSWER HERE**\n",
    "- Do not change cell types or the notebook name.\n",
    "- Do not add other .ipynb files into the ami22 folder or subfolders.\n",
    "- Do not override the original files in the ami22 folder or subfolders.\n",
    "- For every plot makes sure that axes are correctly labeled with original labels and not encoded ones. \n",
    "- If you are asked to provide multiple plots, make sure that the titles are clear. A plot should be self explanatory, we should not have to look at your code to know what is plotted. \n",
    "\n",
    "#### Date of submission: May 11th, 2023, 23:55 hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c854d3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "458cfd8a6d2c0af40bb43efe0458919d",
     "grade": false,
     "grade_id": "cell-160e90c4ef676d59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805562d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61701317745956ca20a947579eb2f4d3",
     "grade": false,
     "grade_id": "cell-4066b9484d9f33f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1 - Metrics\n",
    "You will examine 4 small data sets. Each of them contains only one predictor and one target. First the data will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a1d5eef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ba7f8c256dbb51e0a34e2cca69bcf89",
     "grade": false,
     "grade_id": "cell-ee5d414c9359ff5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.04</td>\n",
       "      <td>9.14</td>\n",
       "      <td>7.46</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.95</td>\n",
       "      <td>8.14</td>\n",
       "      <td>6.77</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>8.74</td>\n",
       "      <td>12.74</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.81</td>\n",
       "      <td>8.77</td>\n",
       "      <td>7.11</td>\n",
       "      <td>8.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.26</td>\n",
       "      <td>7.81</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x0    x1    x2   x3    y0    y1     y2    y3\n",
       "0  10.0  10.0  10.0  8.0  8.04  9.14   7.46  6.58\n",
       "1   8.0   8.0   8.0  8.0  6.95  8.14   6.77  5.76\n",
       "2  13.0  13.0  13.0  8.0  7.58  8.74  12.74  7.71\n",
       "3   9.0   9.0   9.0  8.0  8.81  8.77   7.11  8.84\n",
       "4  11.0  11.0  11.0  8.0  8.33  9.26   7.81  8.47"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ass02_task01_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b651e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3640a04ff45053456c98a940eef4b8b0",
     "grade": false,
     "grade_id": "cell-290774c5fba3d850",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Johannes Daten claims to already have a very versatile model that can predict the respective target y very well for all 4 datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e6b93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a53d4828001fee020789e7387011d453",
     "grade": false,
     "grade_id": "cell-1566c5b5a17599e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 1.1\n",
    "Use the python module pickle to load the model model.sav. Use the variable model to store the loaded estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d6edb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bebe5a83e18199bd18ed56d97dea0a4d",
     "grade": false,
     "grade_id": "cell-ea430cdcf2c591fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237dc350",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "473f8bc41f3955e60b7b7a22458864a3",
     "grade": true,
     "grade_id": "cell-e974f92ea2a73687",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c2ac74c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4834030d98e435904ed96bc2c29b105",
     "grade": false,
     "grade_id": "cell-1da6d20598f2bf2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 1.2\n",
    "To analyze the performance of the model on the different datasets, we need to choose some metrics. We want to use the Root Mean Squared Error (RMSE) and the Pearson Correlation Coefficient, but unfortunately, sklearn has no suitable implementation for it.\n",
    "\n",
    "Implement the two methods `root_mean_squared_error(y, y_pred)` and `r_pearson(y, y_pred)`, where `y` and `y_pred` are arrays with the shape `(num_of_samples, )`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b56d7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "925b36f70514efba182be60c9b79601b",
     "grade": false,
     "grade_id": "cell-332c44b735946f5e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y, y_pred):\n",
    "    # YOUR CODE HERE\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def r_pearson(y, y_pred):\n",
    "    # YOUR CODE HERE\n",
    "    return rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b3f57-98f6-48ea-b4f9-69826efeecab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cc0367db1b5a065110f2d71bc8a0929",
     "grade": true,
     "grade_id": "cell-d0f4269bea1e4446",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b0c96-39e4-44f0-b962-5e6faa8b8777",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46cfd1b266d4b48e9da28de629cc7205",
     "grade": true,
     "grade_id": "cell-83a731f5c80bc44c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb415824",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9defc7fb40fdd26377d8ea599c235328",
     "grade": false,
     "grade_id": "cell-45dd5ef0328be628",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 1.3\n",
    "Now test with the 4 data sets what the model is good for. In the variable `metrics` there are already 4 metric functions which you should use. Calculate your predictions with the help of the loaded model and the corresponding predictor _x0,x1,x2,x3_. Apply the metrics for your respective predictions and the target _y0,y1,y2,y3_. Append the respective result to the list `metlist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7800b85",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca5af2efb1a6fdc0b55aaa4e1a918211",
     "grade": false,
     "grade_id": "cell-c7f1f348c603ea65",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = [mean_squared_error, root_mean_squared_error, r_pearson, r2_score]\n",
    "metlist = []\n",
    "for met in metrics:\n",
    "    # YOUR CODE HERE\n",
    "metdf = pd.DataFrame({'dataset': 4*[0,1,2,3], 'model': 16*['JD'], 'metric': 4*['MSE']+4*['RMSE']+4*['r']+4*['r2'], 'value': metlist})\n",
    "\n",
    "g = sns.FacetGrid(data=metdf, col='metric')\n",
    "g.map(sns.barplot, 'dataset', 'value')\n",
    "plt.plot()\n",
    "metdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5739b2c3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "533877c9e2fdc987aa3c222d11dbe2c2",
     "grade": true,
     "grade_id": "cell-af71289006cce813",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e0af24e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fc99224ef0af34b6fb9618a70be433b",
     "grade": false,
     "grade_id": "cell-b079ab169f786312",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "You suggest to Johannes Daten that he is into dusty old models. You decide to fit a neural network for each data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6c875",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "845d88099ffa42883ccfc471cd84a0bc",
     "grade": false,
     "grade_id": "cell-eb59702d49f39141",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 1.4\n",
    "You are given a for-loop and the list `mlps`. At first, we fit a `StandardScaler` `stsc` to all of the `x` data. Now, create and fit a scikit-learn- `MLPRegressor()` within the for-loop (do not create the `MLPRegressor()` outside) on each of the 4 datasets (i.e. (x0,y0), (x1,y1) and so on). Use the `stsc` to transform the `x` data in each loop before fitting the model. Append each **fitted** estimator to the list `mlps`. Use 3 hidden layers with 128, 64 and 32 neurons. Set the parameters `max_iter=100000` and `n_iter_no_change=1000`. Use `random_state=42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d453a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ead07f1bb7d526abcb517f54d1cc1da5",
     "grade": false,
     "grade_id": "cell-18e1784927081b24",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stsc = StandardScaler()\n",
    "stsc.fit(pd.concat([data.x0, data.x1, data.x2, data.x3]).array.reshape(-1, 1))\n",
    "\n",
    "mlps = []\n",
    "for m in range(0,4):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ada9c8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93311133f353eba6e07b0d16b9b6f856",
     "grade": true,
     "grade_id": "cell-e2b2429ff147d538",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beb4fc60",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62b56635ebdcbda89773f0600f11c782",
     "grade": false,
     "grade_id": "cell-1835238ae7ffc27e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Looking at all 4 data sets, we see that all 4 predictors are in the range between 3 and 20. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9a0dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50744755e0f63f357ce818175af0ebae",
     "grade": false,
     "grade_id": "cell-5632196dc0ebe96a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 1.5\n",
    "Create a variable `x` with 100 values ranging from 3 to 20. The 3 and 20 should be included. Predict the y-values to these x-values with the model `mlps[0]` and the model `model`. Remember, that for the prediction of the MLP you have to apply the `StandardScaler` on your x-values again. Store your predictions in the variables `y_mlp0` and `y_jd`. A plot will be generated for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80abde",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f82ddc7f334fd37ad5f621866e09d165",
     "grade": false,
     "grade_id": "cell-d605a65cab73c551",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "f,a = plt.subplots(2,2, figsize=(10,7))\n",
    "a = a.ravel()\n",
    "for p in range(0,4):\n",
    "    sns.lineplot(x=x,y=y_mlp0,ax=a[p],label='mlp0', linestyle='--')\n",
    "    sns.lineplot(x=x,y=y_jd,ax=a[p],label='JD',linestyle=':')\n",
    "    sns.scatterplot(x=data.iloc[:,p],y=data.iloc[:,4+p],ax=a[p], color='g')\n",
    "    a[p].set_title('dataset ' + str(p))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d68378",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1f7b4365a2c4c0ccdfb838928251678",
     "grade": true,
     "grade_id": "cell-e941f5213cabc88e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb56f5a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf8b19161ae5533632d4666f266e2b81",
     "grade": true,
     "grade_id": "cell-60e27eb0704cc822",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bf7256",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "accfb1bc840064a37f8bc250c9149fa8",
     "grade": true,
     "grade_id": "cell-a3757e4d9721cc41",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed156709",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f20271590aa571761c8636ce1c540b4",
     "grade": false,
     "grade_id": "cell-b83824d279311f30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "\n",
    "\n",
    "SVG(filename='metrics.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43bd9e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "200dd55bdfabd168a0f62ed53952f4d8",
     "grade": false,
     "grade_id": "cell-94ccf2be0a3a568c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 1.6\n",
    "Given the plots from task 1.5 and the visualization of the 4 metrics for some of the models (if you are also interested in the performance of the MLP fitted on dataset 2 and dataset 3 - go ahead in an own notebook and try it ... but not in this assignment.) which of the following statements is correct?\n",
    "<br>\n",
    "<br>\n",
    "'a': mlp[0] and mlp[1] are overfitted.\n",
    "<br>\n",
    "<br>'b': Johannes Daten's model is overfitted.\n",
    "<br>\n",
    "<br>'c': Neural Networks are robust against overfitting.\n",
    "<br>\n",
    "<br>'d': Overfitting is not as bad as underfitting, since only underfitting generates models with over-optimistic performance predictions.\n",
    "<br>\n",
    "<br>\n",
    "_Use a variable x16 and assign your answer of the question (if 'e' would be the correct answer your code should look like this: x16='e'. There is only one correct answer._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57eb95e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "427b85350e58d301f11c0a3e05c5cf34",
     "grade": false,
     "grade_id": "cell-05c5cc285bcb4b9d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "print('The answer is ' + x16 + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0989f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c84d3008bd3070a7bfa07005471d621",
     "grade": true,
     "grade_id": "cell-5c48bc598e9ed3d5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49804f8e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d83bfab105b8c2de4106bcc8347e9f6",
     "grade": false,
     "grade_id": "cell-416496ce8786449c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 2 - Active Learning\n",
    "In the following task you will have a look at a simple binary classification problem where you will be using active learning to help your model learn faster. \n",
    "\n",
    "We have an array of training samples `X_train`, but unfortunately, there are no labels yet. To get access to labels, we can ask an omnisicient `oracle`, but this is costly and we should use it as little as possible. We train our model in several rounds, where each round we add one label by either using random or uncertainty sampling.\n",
    "\n",
    "To check how our model is learning, we can evaluate the performance on a labelled test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c73fcd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a776c059d81d1dc605bb9896f0c03733",
     "grade": false,
     "grade_id": "cell-25bc4c78ef81b176",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"ass02_task02_train.csv\")\n",
    "oracle = pd.read_csv(\"ass02_task02_oracle.csv\")\n",
    "\n",
    "test = pd.read_csv(\"ass02_task02_test.csv\")\n",
    "X_test = test.drop(columns=[\"y\"])\n",
    "y_test = test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37b4cf-60bd-45fc-b356-b1a435b21087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1)\n",
    "sns.scatterplot(X_train, x=\"X1\", y=\"X2\", ax=axs)\n",
    "axs.set_title(\"Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c9588-affd-46a2-bdaf-acd8e79b0e96",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46be11885b57b6b0986df2f8336540f7",
     "grade": false,
     "grade_id": "cell-36b27440e9615b70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 2.1\n",
    "\n",
    "First, you should set a benchmark. For this you use all labels provided by the oracle and the whole training set. Use the logistic regression from scikit as a model. To not complicate the task we use the default parameters. Use the variable name `lr_clf` for the classifier. After fitting, compute the accuracy score on the test set and store it to `acc_bm`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c7065",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "629b03ed462ecef5e9be9900606e7bbc",
     "grade": false,
     "grade_id": "cell-0550e7bf9246a1cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"Benchmark accuracy: {acc_bm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70164dad-b624-48fc-a984-87918a2ebf76",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5e4d9edacc4a4b20856eeae493938b1",
     "grade": true,
     "grade_id": "cell-9071f24183f2f73f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5e65c-735a-4171-b2ec-6ee4db86482b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb5933ce2e439c0389de66e02d3f43fb",
     "grade": true,
     "grade_id": "cell-bb5f839756c76f34",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b031689b-6d1d-42ee-9352-1bce916095c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8274aa501800515363dec122c1c2f2ea",
     "grade": false,
     "grade_id": "cell-6bd6c26e4e343de0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 2.2\n",
    "In the following task you will implement the so called _random sampling_ strategy to select a sample that has not yet been used for training. \n",
    "Use the already given function `random_sampling()`, which receives as input the whole training set `X_train` and the indices of the samples already used for training `train_indices`. Your function returns the new index.\n",
    "\n",
    "*Hint: Use the `seed()` and `choice()` methods provided by the `random` package. Set the random seed to 42!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436fd618-6017-4c08-842d-df8b2c329bc2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abf8df9bc96d3ab59402e20f1c3ce199",
     "grade": false,
     "grade_id": "cell-98276c94e473eea1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_sampling(X_train, train_indices, model=None) -> int:\n",
    "    # YOUR CODE HERE\n",
    "    return new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaec46e-294b-4ddb-866a-f0629245f501",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6b1d5a8654affde96f9617d98eee3d0",
     "grade": true,
     "grade_id": "cell-ddf099e179766889",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7f1b7f6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72621daa2dcc6e6f28f6fbbe953aa2df",
     "grade": false,
     "grade_id": "cell-b3cb7dcdb54fb929",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 2.3\n",
    "Now we train several Logistic Regression models. At first, train a model only with the samples with the indices 7 and 25, you can get the labels from the oracle.\n",
    "\n",
    "Afterwards, in each of the 30 rounds, fetch one additional label using your `random_sampling` method and train another Logistic Regression model.\n",
    "\n",
    "Store the accuracies on the test data in the `accs_rs` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085b234",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c5867c0cefa221139424ea639aab284",
     "grade": false,
     "grade_id": "cell-64b3351230746b1d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accs_rs = []\n",
    "train_indices = [7, 25]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for _ in range(30):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9de1b4-c913-4e89-927d-5cbeaa30ccea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1e9d2c11dc20ca6ccb4bf373296599f",
     "grade": true,
     "grade_id": "cell-8268222ec85c6d80",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c0a8bb-b0ee-4eee-84d4-23490bebc2b7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9054742a86db0363898331f135e9f4f",
     "grade": true,
     "grade_id": "cell-bb1ca5536e897b22",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bf1f50e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "775341c90af4261bd17cc9dd1e103217",
     "grade": false,
     "grade_id": "cell-6141a4c549e2eceb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Task 2.4\n",
    "Now we use a more sophisticated way to choose the next training sample, by evaluating the uncertainty of the model.\n",
    "\n",
    "Use the already given function `random_sampling()`, which receives as input the whole training set `X_train`, the indices of the samples already used for training `train_indices` and the current fitted model `lr`. Your function returns the new index of the training set that has not been used for training and that has the highest uncertainty.\n",
    "\n",
    "*Hint: Calculate the probabilities for each unseen training sample using the function `predict_proba()` provided by sklearn's `SVC` classifier.*\n",
    "\n",
    "*Determine then the new index by choosing the sample with the highest uncertainty (entropy).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789be2a5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c48994caa6019a58ed474032a224703",
     "grade": false,
     "grade_id": "cell-f6427319b59b16d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def uncertainty_sampling(X_train, train_indices, model) -> int:\n",
    "    # YOUR CODE HERE\n",
    "    return new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3825ddb-b4e2-4206-9f04-445c3cc4cc2e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e02bb7b5cc873d8a45e2217355b9423",
     "grade": true,
     "grade_id": "cell-0119680c329b2a9e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e8c04-4aa2-48ad-83e1-7c131b14a30c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "013236d3afc76fbdb7cc5acfc697fcb1",
     "grade": true,
     "grade_id": "cell-42df07ab0cc9793e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72ede1dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25a3b753a236d6b0c33130677caa80de",
     "grade": false,
     "grade_id": "cell-2456f4309dee6d41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 2.5\n",
    "Again, we train several Logistic Regression models. At first, train a model only with the samples with the indices 7 and 25, you can get the labels from the oracle.\n",
    "\n",
    "Afterwards, in each of the 30 rounds, fetch one additional label using your `uncertainty_sampling` method and train another Logistic Regression model.\n",
    "\n",
    "Store the accuracies on the test data in the `accs_us` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d93ae1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee56edd7eeeb3c1c8f6416e1db86f9f4",
     "grade": false,
     "grade_id": "cell-fe00fa8878f42736",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accs_us = []\n",
    "train_indices = [7, 25]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for _ in range(30):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eada190-38ad-42da-818d-057de9cf60df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55f3e116816aa5a3b0545e00153423b5",
     "grade": true,
     "grade_id": "cell-205f5d802d68a688",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96e1c634",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e561b508287230a337c74a20f3cc164",
     "grade": false,
     "grade_id": "cell-93697ea364c3780c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualizing the result\n",
    "Using the below code cell you can visualize how the performance of our models improved while adding further labels to the training. \n",
    "\n",
    "If you correctly implemented the previous tasks, you can observe the following: even if at the beginning uncertainty sampling has a similar low point has random sampling, it quickly improves its performance and even outperforms the benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e513b-56b1-499d-b4d3-da1e091ff7e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "733a9fc8e9ecfba69d0c846c3eed84a3",
     "grade": false,
     "grade_id": "cell-6c4dbacee7888215",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1)\n",
    "sns.lineplot(accs_rs, ax=axs, label=\"random sampling\")\n",
    "sns.lineplot(accs_us, ax=axs, label=\"uncertainty sampling\")\n",
    "axs.axhline(y=acc_bm, linestyle=\"--\", color=\"grey\", label=\"benchmark\")\n",
    "\n",
    "axs.set_xlabel(\"Number of additonally sampled labels\")\n",
    "axs.set_ylabel(\"Accuracy\")\n",
    "axs.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
